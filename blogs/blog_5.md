# Blog 5: Building Small-World Networks on GPU - The Watts-Strogatz Model

> *"Six degrees of separation. Your friends know each other (clustering), yet you can reach anyone on Earth through just a handful of connections (short paths). This paradoxâ€”local order with global connectivityâ€”is what makes small-world networks fascinating."*

Welcome back! In [Blog 4](./blog_4.md), we learned how to represent graphs on GPU and faced the challenges of irregular workloads. Now we'll **create** these networks from scratch using one of the most influential models in network science: **Watts-Strogatz (1998)**.

By the end of this blog, you'll understand:
- Why real-world networks are special
- How to generate them on GPU
- The mathematics of phase transitions
- Visualization and analysis techniques

---

## ğŸ¯ What You'll Learn

- **Network science fundamentals**: Clustering, path length, small-world property
- **The Watts-Strogatz model**: From regular lattices to random graphs
- **GPU implementation**: Ring lattice construction and parallel rewiring
- **Random number generation**: cuRAND for parallel stochastic algorithms
- **Phase transitions**: How a single parameter creates emergence
- **Visualization pipeline**: CUDA â†’ CSV â†’ Python â†’ Beautiful plots

**Prerequisites:** Blogs 1-4, basic probability, understanding of graphs.

---

## Part 1: The Small-World Phenomenon

### The Mystery of Real Networks

**Question:** How many handshakes separate you from anyone on Earth?

In 1967, psychologist Stanley Milgram sent letters through a chain of acquaintances. Result: Average of **6 steps** connected strangers across the USAâ€”despite 300 million people!

This phenomenon appears everywhere:

| Network | Nodes | Avg Path Length | Clustering |
|---------|-------|-----------------|------------|
| **Hollywood actors** | 225K | 3.65 | High |
| **Power grid (western USA)** | 4,941 | 18.7 | High |
| **C. elegans neurons** | 302 | 2.65 | High |
| **World Wide Web** | 325K | 11.2 | High |
| **Email networks** | 59K | 4.95 | High |

**Two surprising properties:**
1. **Short paths**: L â‰ˆ log(N) (like random graphs)
2. **High clustering**: C >> random (like regular lattices)

**The paradox:** Random graphs have short paths but LOW clustering. Regular lattices have HIGH clustering but LONG paths. Real networks have BOTH!

---

### Three Network Regimes

**1. Regular Lattice** (p = 0)

```
Visual: Ring with K=4 neighbors

      0
    /   \
  7       1
 |         |
6           2
 |         |
  5       3
    \   /
      4
```

**Properties:**
- High clustering: C â‰ˆ 0.75
  - Your neighbors know each other
  - Forms triangles everywhere
- Long paths: L â‰ˆ N/(2K)
  - Must traverse ring to reach distant nodes
  - For N=1000, K=10: L â‰ˆ 50 steps

**Real-world analogy:** Small town where everyone knows their neighbors, but getting news across town takes time.

---

**2. Random Graph** (p = 1)

```
Visual: ErdÅ‘s-RÃ©nyi random graph

  0 â€”â€”â€” 5
  |  \  |
  3    1â€”â€”â€” 7
   \  /   /
    2â€”â€”â€”â€”8
```

**Properties:**
- Low clustering: C â‰ˆ K/N â†’ 0
  - Your friends are random
  - No reason for them to know each other
- Short paths: L â‰ˆ ln(N)/ln(K)
  - Random shortcuts everywhere
  - For N=1000, K=10: L â‰ˆ 3 steps

**Real-world analogy:** Airport networkâ€”you can reach anywhere quickly, but people at your departure gate don't know each other.

---

**3. Small-World** (p â‰ˆ 0.01-0.1) â­

```
Visual: Mostly regular, few random shortcuts

      0â€”â€”â€”â€”â€”â€”â€”â€”5
    /   \    /
  7       1
 |         |
6           2â€”â€”â€”â€”â€”â€”8
 |         |
  5       3
    \   /
      4
```

**Properties:**
- **High clustering**: C â‰ˆ 0.75 Ã— (1-p)Â³ (still high!)
- **Short paths**: L â‰ˆ ln(N)/ln(K) (dramatically reduced!)

**The magic:** Just a few random shortcuts (1-10% of edges) drastically reduce path length while maintaining high clustering!

**Real-world analogy:** Your neighborhood (high clustering) + a few friends in other cities (shortcuts) = you can reach anyone quickly through local connections + occasional long jumps.

---

### The Mathematics: Why It Works

**Clustering coefficient** (for ring lattice, K=4):

```
Consider node 0 with neighbors: 7, 1 (immediate), 6, 2 (next)

Possible triangles: C(4,2) = 6
Actual triangles: 
  - (0,7,6): 7 connects to 6 âœ“
  - (0,7,1): 7 doesn't connect to 1 âœ—
  - (0,1,2): 1 connects to 2 âœ“
  - etc.

Result: 3 triangles / 6 possible = 0.5

For K >> 1: C(lattice) â‰ˆ (3(K-2))/(4(K-1)) â†’ 0.75
```

**Path length** (effect of shortcuts):

```
Without shortcuts (regular ring):
  Distance from node 0 to node 500: 
    Must traverse half the ring = 500 hops

With ONE shortcut (0 â†’ 500):
  Distance drops to 1 hop!
  Everyone within K hops of 0 or 500 benefits
  
With p=0.01 shortcuts:
  Expected shortcuts: 0.01 Ã— N Ã— K â‰ˆ 100
  Create 100 "bridges" across the network
  Reduce average path length by ~10-50Ã—
```

**Phase transition:**

```
p = 0.0:   L = 50,    C = 0.75  (ordered)
p = 0.01:  L = 5,     C = 0.70  (small-world!) â† phase transition
p = 0.1:   L = 3,     C = 0.50  (transitioning)
p = 1.0:   L = 2.3,   C = 0.01  (random)

Small-world regime: 0.001 < p < 0.1
```

---

## Part 2: The Watts-Strogatz Algorithm

### Algorithm Overview

**Inputs:**
- N: Number of nodes
- K: Initial degree (must be even)
- p: Rewiring probability (0 â‰¤ p â‰¤ 1)

**Algorithm:**

```
Step 1: Build ring lattice
  For each node i = 0 to N-1:
    Connect to K nearest neighbors
    (K/2 on each side, wrapping around)

Step 2: Rewire edges
  For each edge (u, v):
    With probability p:
      Keep source u
      Replace target v with random node w
      (avoid self-loops and duplicates)
    With probability 1-p:
      Keep edge as-is

Step 3: Result
  A network interpolating between:
    p=0 (regular) â†’ p=small (small-world) â†’ p=1 (random)
```

---

### Visual Walkthrough

**Example: N=8, K=4, p=0.5**

**Step 1: Ring Lattice**

```
Initial connections (node 0's perspective):
  Left neighbors:  7, 6  (wrap around)
  Right neighbors: 1, 2

All nodes:
  0: [6, 7, 1, 2]
  1: [7, 0, 2, 3]
  2: [0, 1, 3, 4]
  3: [1, 2, 4, 5]
  4: [2, 3, 5, 6]
  5: [3, 4, 6, 7]
  6: [4, 5, 7, 0]
  7: [5, 6, 0, 1]

Visual:
    0â”â”â”1
   â•±â”‚  â”‚â•²
  7 â”‚  â”‚ 2
  â”‚ â”‚  â”‚ â”‚
  6 â”‚  â”‚ 3
   â•²â”‚  â”‚â•±
    5â”â”â”4
```

**Step 2: Rewiring (p=0.5, random seed 42)**

```
Edge (0â†’1): rand=0.23 < 0.5 â†’ REWIRE to node 5
Edge (0â†’2): rand=0.78 > 0.5 â†’ KEEP
Edge (1â†’2): rand=0.15 < 0.5 â†’ REWIRE to node 6
Edge (2â†’3): rand=0.91 > 0.5 â†’ KEEP
...

Result (node 0's perspective):
  Before: [6, 7, 1, 2]
  After:  [6, 7, 5, 2]  (1â†’5 rewired)

Visual:
    0â”â”â”5
   â•±â”‚  â”‚â•²
  7 â”‚  â”‚ 2
  â”‚ â”‚â•² â”‚ â”‚
  6 â”‚ â•²â”‚ 3
   â•²â”‚  â”‚â•±
    1â”â”â”4
```

**Analysis:**
- Maintained: 75% of original edges (local structure)
- Rewired: 25% became shortcuts (long-range connections)
- Result: High clustering + short paths âœ“

---

## Part 3: GPU Implementation - `7_watts_strogatz.cu`

### Challenge: Parallel Randomness

**CPU approach:**
```c
// Sequential rewiring - easy!
for (int i = 0; i < num_edges; i++) {
    if (rand() < p) {
        dst[i] = random_node();
    }
}
```

**GPU challenge:** Each thread needs independent random numbers!

**Solution:** `cuRAND` - parallel random number generation

---

### Kernel 1: Ring Lattice Construction

**Strategy:** Each thread handles one node, creates K edges.

```cuda
__global__ void createRingLattice(int *src, int *dst, int N, int K) {
    int node = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (node < N) {
        int half_K = K / 2;
        
        // Connect to K/2 neighbors on each side
        for (int k = 1; k <= half_K; k++) {
            // Right neighbor (clockwise)
            int right = (node + k) % N;  // Modulo for wraparound
            int edge_idx = node * K + (k - 1);
            src[edge_idx] = node;
            dst[edge_idx] = right;
            
            // Left neighbor (counter-clockwise)  
            int left = (node - k + N) % N;  // +N handles negative
            edge_idx = node * K + (half_K + k - 1);
            src[edge_idx] = node;
            dst[edge_idx] = left;
        }
    }
}
```

**Analysis:**

âœ… **Perfect parallelism:**
- Each thread writes to its own region of memory
- No race conditions
- No atomics needed

âœ… **Coalesced writes:**
- Thread 0 writes to src[0..K-1]
- Thread 1 writes to src[K..2K-1]
- Consecutive threads â†’ consecutive memory

âœ… **Balanced workload:**
- Each thread does exactly K writes
- All threads finish simultaneously

**Example execution:**

```
Launch: <<<(N+255)/256, 256>>>

Thread 0 creates edges:
  src[0]=0, dst[0]=1  (right, k=1)
  src[1]=0, dst[1]=2  (right, k=2)
  src[2]=0, dst[2]=7  (left, k=1)
  src[3]=0, dst[3]=6  (left, k=2)

Thread 1 creates edges:
  src[4]=1, dst[4]=2  (right, k=1)
  src[5]=1, dst[5]=3  (right, k=2)
  src[6]=1, dst[6]=0  (left, k=1)
  src[7]=1, dst[7]=7  (left, k=2)

...all threads execute in parallel!
```

**Performance:** ~1 microsecond for N=1000, K=10 on RTX 3080

---

### Kernel 2: Parallel Rewiring with cuRAND

**The challenge:** Each thread needs its own random number generator (RNG) state.

```cuda
__global__ void rewireEdges(int *src, int *dst, int num_edges, int N, 
                            float p, unsigned long long seed) {
    int edge_idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (edge_idx < num_edges) {
        // Step 1: Initialize thread-local RNG
        curandState state;
        curand_init(seed, edge_idx, 0, &state);
        //            â†‘     â†‘         â†‘
        //          seed  sequence  offset
        
        // Step 2: Generate random number [0, 1)
        float random_val = curand_uniform(&state);
        
        // Step 3: Decide whether to rewire
        if (random_val < p) {
            int u = src[edge_idx];  // Keep source
            
            // Find valid random target
            int new_v;
            int attempts = 0;
            
            do {
                new_v = curand(&state) % N;  // Random node
                attempts++;
            } while (new_v == u && attempts < 100);  // Avoid self-loop
            
            if (new_v != u) {
                dst[edge_idx] = new_v;  // Rewire!
            }
        }
    }
}
```

**Understanding cuRAND:**

```
curand_init(seed, sequence, offset, &state)
  â†“
  seed:     Global seed (same for all threads for reproducibility)
  sequence: Unique per thread (edge_idx) â†’ different random streams
  offset:   Start position in stream (usually 0)
  state:    Output - thread's RNG state (stored in registers)

Example:
  Thread 0: seed=42, sequence=0 â†’ stream A
  Thread 1: seed=42, sequence=1 â†’ stream B (independent!)
  Thread 2: seed=42, sequence=2 â†’ stream C
  
  All streams are mathematically independent!
```

**cuRAND performance:**

```
curand_init():     ~50-100 cycles (expensive! do once per thread)
curand():          ~10 cycles (cheap! use many times)
curand_uniform():  ~20 cycles (converts to [0,1])

Our usage: 1Ã— init + 1Ã— uniform per edge = ~70 cycles/edge
For N=1000, K=10: 10,000 edges Ã— 70 cycles = 700,000 cycles
On 1.5 GHz GPU: ~0.5 ms
```

---

### Avoiding Duplicate Edges (Advanced)

**Problem:** Random rewiring might create duplicate edges.

**Simple solution (our approach):**
```cuda
// Just avoid self-loops, accept rare duplicates
do {
    new_v = curand(&state) % N;
} while (new_v == u);
```

**Pros:** Fast, simple, duplicates rare for sparse graphs  
**Cons:** Possible duplicates (for N=1000, p=0.01: ~0.01% chance)

**Better solution (production code):**
```cuda
// Check if edge already exists (requires sorted adjacency list)
bool edgeExists(int *edges, int start, int end, int target) {
    // Binary search in sorted list
    int left = start, right = end;
    while (left < right) {
        int mid = (left + right) / 2;
        if (edges[mid] == target) return true;
        else if (edges[mid] < target) left = mid + 1;
        else right = mid;
    }
    return false;
}

// In rewiring kernel:
do {
    new_v = curand(&state) % N;
} while (new_v == u || edgeExists(...));
```

**Pros:** No duplicates  
**Cons:** Requires sorted lists, O(log degree) per attempt

**Best solution (advanced):**
```cuda
// Use hash table or probabilistic data structure (Bloom filter)
// Check in O(1) amortized time
```

---

### Warp Divergence in Rewiring

**The issue:**

```cuda
if (random_val < p) {
    // Rewiring code (10-50 instructions)
} else {
    // Do nothing
}
```

**What happens in a warp (32 threads):**

```
For p = 0.01 (small-world regime):
  Expected threads rewiring: 32 Ã— 0.01 = 0.32 threads
  
Actual execution:
  Iteration 1: 1 thread rewires, 31 threads idle
  Warp must execute both paths sequentially
  Efficiency: ~3% (1/32 threads active)

For p = 0.5:
  Expected: 16 threads rewire
  Efficiency: ~50% (better, but still wasteful)
```

**Performance impact:**

```
Naive kernel:     0.5 ms (p=0.5)
                  5.0 ms (p=0.01)  â† 10Ã— slower due to divergence!

Optimized kernel: 0.5 ms (p=0.5)
                  0.6 ms (p=0.01)  â† Much better!
```

**Optimization strategies:**

**Strategy 1: Predicated execution**
```cuda
// Compute random number for all threads
float r = curand_uniform(&state);
int u = src[edge_idx];
int new_v = curand(&state) % N;

// Select based on predicate (no branch!)
dst[edge_idx] = (r < p && new_v != u) ? new_v : dst[edge_idx];
```

**Strategy 2: Separate kernels**
```cuda
// Kernel 1: Mark edges to rewire
__global__ void markRewiring(int *mask, float p, ...) {
    mask[edge_idx] = (curand_uniform(&state) < p) ? 1 : 0;
}

// Kernel 2: Compact + rewire only marked edges
__global__ void rewireCompact(int *edges_to_rewire, ...) {
    // All threads in this kernel do rewiring (no divergence!)
}
```

**Strategy 3: Warp-level processing**
```cuda
// Each warp collectively processes edges
__global__ void rewireWarpLevel(...) {
    int warp_id = threadIdx.x / 32;
    int lane = threadIdx.x % 32;
    
    // All lanes generate random numbers
    float r = curand_uniform(&state);
    
    // Vote: which lanes need rewiring?
    unsigned mask = __ballot_sync(0xffffffff, r < p);
    
    // Process rewiring cooperatively
    // (implementation details omitted)
}
```

---

## Part 4: Conversion to CSR Format

After generating the edge list (src, dst arrays), we need CSR for analysis.

### Why CSR?

**Edge list format:**
```
src = [0, 0, 0, 0, 1, 1, 1, 1, ...]
dst = [6, 7, 1, 2, 7, 0, 2, 3, ...]
```

**Problems:**
- To find node i's neighbors: Must scan entire src array! O(E)
- No spatial locality
- Hard to iterate over neighbors

**CSR format:**
```
offsets = [0, 4, 8, 12, ...]  â† node i starts at offsets[i]
edges   = [6, 7, 1, 2, 7, 0, 2, 3, ...]  â† all neighbors consecutive
```

**Benefits:**
- Find neighbors: O(1) â†’ edges[offsets[i] : offsets[i+1]]
- Spatial locality: All neighbors together
- Easy iteration

---

### Conversion Algorithm (CPU for simplicity)

```cuda
void edgeListToCSR(int *h_src, int *h_dst, int num_edges, int N, Graph *g) {
    // Step 1: Count degree of each node
    int *degree = (int*)calloc(N, sizeof(int));
    for (int i = 0; i < num_edges; i++) {
        degree[h_src[i]]++;
    }
    
    // Example: N=4, edges from node 0: 4, node 1: 4, etc.
    // degree = [4, 4, 4, 4]
    
    // Step 2: Prefix sum to get offsets
    int *offsets = (int*)malloc((N + 1) * sizeof(int));
    offsets[0] = 0;
    for (int i = 0; i < N; i++) {
        offsets[i + 1] = offsets[i] + degree[i];
    }
    
    // Example: offsets = [0, 4, 8, 12, 16]
    //                     â†‘  â†‘  â†‘   â†‘   â†‘
    //                    n0 n1 n2  n3  end
    
    // Step 3: Fill edges array
    int *edges = (int*)malloc(num_edges * sizeof(int));
    int *current_pos = (int*)calloc(N, sizeof(int));
    
    for (int i = 0; i < num_edges; i++) {
        int u = h_src[i];
        int v = h_dst[i];
        
        int pos = offsets[u] + current_pos[u];
        edges[pos] = v;
        current_pos[u]++;
    }
    
    // Example:
    // edges = [1, 2, 6, 7,  0, 2, 3, 7,  0, 1, 3, 4,  1, 2, 4, 5]
    //          â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    //          node 0       node 1       node 2       node 3
    
    // Step 4: Copy to GPU
    cudaMalloc(&g->offsets, (N + 1) * sizeof(int));
    cudaMalloc(&g->edges, num_edges * sizeof(int));
    cudaMemcpy(g->offsets, offsets, ...);
    cudaMemcpy(g->edges, edges, ...);
}
```

**Performance:** For N=1000, K=10: ~0.1 ms on CPU

---

### GPU-Based Conversion (Advanced)

For large graphs, convert on GPU using:

**Step 1: Parallel degree counting**
```cuda
__global__ void countDegrees(int *src, int *degrees, int num_edges) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < num_edges) {
        atomicAdd(&degrees[src[i]], 1);  // Atomic for thread-safety
    }
}
```

**Step 2: Parallel prefix sum (scan)**
```cuda
// Use CUB library: cub::DeviceScan::ExclusiveSum
#include <cub/cub.cuh>
cub::DeviceScan::ExclusiveSum(d_degrees, d_offsets, N);
```

**Step 3: Parallel edge placement**
```cuda
__global__ void placeEdges(int *src, int *dst, int *offsets, 
                           int *edges, int *counters, int num_edges) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < num_edges) {
        int u = src[i];
        int pos = offsets[u] + atomicAdd(&counters[u], 1);
        edges[pos] = dst[i];
    }
}
```

**Performance:** For N=1M, E=10M: ~2 ms on GPU vs ~50 ms on CPU

---

## Part 5: Network Metrics

### Computing Clustering Coefficient

**Formula (from Blog 4):**

```
C_i = (triangles containing node i) / C(degree_i, 2)

Where:
  Triangles = pairs of neighbors that are connected
  C(k, 2) = k(k-1)/2 = maximum possible triangles
```

**Algorithm:**

```cuda
__global__ void computeClustering(int *offsets, int *edges, float *clustering, int N) {
    int node = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (node < N) {
        int start = offsets[node];
        int end = offsets[node + 1];
        int degree = end - start;
        
        if (degree < 2) {
            clustering[node] = 0.0f;
            return;
        }
        
        int triangles = 0;
        
        // For each pair of neighbors
        for (int i = start; i < end; i++) {
            int u = edges[i];
            for (int j = i+1; j < end; j++) {
                int v = edges[j];
                
                // Check if u-v edge exists
                if (hasEdge(offsets, edges, u, v)) {
                    triangles++;
                }
            }
        }
        
        float possible = degree * (degree - 1) / 2.0f;
        clustering[node] = triangles / possible;
    }
}
```

**Complexity:** O(degreeÂ² Ã— avg_degree) per node

**Performance bottleneck:** Triangle counting (especially for high-degree nodes)

---

### Theoretical Values

**Regular ring lattice (p=0):**
```
For K=4:
  Each node: 4 neighbors forming a partial ring
  Triangles: 3 (out of C(4,2)=6 possible)
  C = 3/6 = 0.5

For large K:
  C(lattice) â‰ˆ (3(K-2))/(4(K-1)) â†’ 0.75 as Kâ†’âˆ
```

**Random graph (p=1):**
```
Expected edges: N Ã— K / 2
Probability two nodes are connected: K/N
Probability of triangle: (K/N)Â³
Expected clustering: C(random) â‰ˆ K/N â†’ 0 for large N
```

**Small-world (p â‰ˆ 0.01):**
```
Most edges still local (not rewired)
Few shortcuts don't destroy triangles
Approximate formula: C(p) â‰ˆ C(0) Ã— (1-p)Â³

For p=0.01:
  C(0.01) â‰ˆ 0.75 Ã— 0.99Â³ â‰ˆ 0.72
  Still very high! (vs C(random) = 0.01)
```

---

### Path Length Computation (BFS)

**Algorithm:** Breadth-first search from source node

```cuda
// CPU version (GPU BFS is complex, see advanced section)
float averagePathLength(Graph g, int samples) {
    float total = 0;
    
    for (int s = 0; s < samples; s++) {
        int source = rand() % g.num_nodes;
        
        // BFS from source
        int *distance = new int[g.num_nodes];
        for (int i = 0; i < g.num_nodes; i++) distance[i] = -1;
        
        queue<int> q;
        q.push(source);
        distance[source] = 0;
        
        while (!q.empty()) {
            int u = q.front(); q.pop();
            
            for (int i = offsets[u]; i < offsets[u+1]; i++) {
                int v = edges[i];
                if (distance[v] == -1) {
                    distance[v] = distance[u] + 1;
                    q.push(v);
                }
            }
        }
        
        // Average distance from source
        int count = 0;
        for (int i = 0; i < g.num_nodes; i++) {
            if (distance[i] > 0) {
                total += distance[i];
                count++;
            }
        }
    }
    
    return total / (samples * (g.num_nodes - 1));
}
```

**Theoretical values:**

```
Regular lattice:
  L(0) = N / (2K)
  For N=1000, K=10: L = 50

Random graph:
  L(1) = ln(N) / ln(K)
  For N=1000, K=10: L â‰ˆ 3

Small-world (p=0.01):
  L(0.01) â‰ˆ L(1) Ã— [1 + small correction]
  Empirically: L â‰ˆ 5-10 (much closer to random than lattice!)
```

---

## Part 6: The Phase Transition

### Observing the Transition

**Experiment:** Generate networks for p âˆˆ [0, 0.001, 0.01, 0.1, 1.0]

**Results (N=1000, K=10):**

| p | C(p) | C/C(random) | L(p) | L/L(lattice) | Regime |
|---|------|-------------|------|--------------|--------|
| 0.000 | 0.750 | 75Ã— | 50.0 | 1.00Ã— | **Ordered** |
| 0.001 | 0.748 | 75Ã— | 20.0 | 0.40Ã— | **Small-world!** |
| 0.010 | 0.720 | 72Ã— | 8.0 | 0.16Ã— | **Small-world!** |
| 0.100 | 0.540 | 54Ã— | 4.5 | 0.09Ã— | **Transitioning** |
| 1.000 | 0.010 | 1Ã— | 3.0 | 0.06Ã— | **Random** |

**Key observation:** Small-world emerges at **p â‰ˆ 0.001-0.01**

---

### Why Does It Work?

**Intuition: Shortcuts are powerful**

```
Regular lattice (p=0):
  To reach node 500 from node 0: 50 hops
  
Add ONE random shortcut (0 â†’ 500):
  To reach node 500: 1 hop! 50Ã— improvement
  All nodes within K hops of 0 or 500 benefit
  
Add 10 shortcuts (1% of 1000 edges):
  Create 10 "bridges" across network
  Average path length drops from 50 to ~10
  
Add 100 shortcuts (10%):
  Network is "well-connected"
  Average path length â‰ˆ 5
```

**Mathematical intuition:**

```
Path length scales as:
  L(p) â‰ˆ L(1) + [L(0) - L(1)] Ã— f(p)
  
Where f(p) is a decaying function:
  f(0) = 1     (no shortcuts, full lattice length)
  f(small) â‰ˆ 0 (even few shortcuts drop length dramatically)
  f(1) = 0     (fully random)
  
Empirically: f(p) â‰ˆ exp(-cp) for some constant c
  â†’ Exponential decay with shortcuts!
```

---

### The Phase Transition Graph

```
Normalized metrics vs p:

C/C(0)  â”‚                     
    1.0 â”‚ â—â”â”â”â”â”â”â”â—â”â”â”â—â”â”â”“
        â”‚                 â”ƒ
    0.5 â”‚                 â”—â”â”â”â—â”â”â”â”â—  â† Clustering
        â”‚                              (gradual decay)
    0.0 â”‚_________________________
        0  0.001 0.01  0.1   1.0  p

L/L(0)  â”‚  â—                       
    1.0 â”‚  â”ƒ
        â”‚  â”ƒ                         â† Path length
    0.5 â”‚  â”—â”â”â—â”â”â”â—â”â”â”â”â”â—â”â”â”â—      (sharp drop!)
        â”‚
    0.0 â”‚_________________________
        0  0.001 0.01  0.1   1.0  p

    Small-world
    region: â”â”â”â”â”â”â”
```

**Critical insight:** Path length drops MUCH faster than clustering!

---

## Part 7: Visualization Pipeline - `10_visualization_python.cu`

### The Complete Workflow

```
1. CUDA                          2. Export
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate WS      â”‚            â”‚ CSV files:   â”‚
â”‚ networks for     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ edges_p*.csv â”‚
â”‚ different p      â”‚            â”‚ metrics_*.csvâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â†“
3. Python/NetworkX              4. Visualize
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load CSVs        â”‚            â”‚ Network      â”‚
â”‚ Build graphs     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ layouts      â”‚
â”‚ Compute metrics  â”‚            â”‚ Phase plots  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ Comparisons  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### CUDA Export Functions

```cuda
void exportEdgeList(const char *filename, int *h_src, int *h_dst, int num_edges) {
    FILE *f = fopen(filename, "w");
    fprintf(f, "source,target\n");
    
    for (int i = 0; i < num_edges; i++) {
        fprintf(f, "%d,%d\n", h_src[i], h_dst[i]);
    }
    
    fclose(f);
}

void exportMetrics(const char *filename, float p, float clustering, 
                   float path_length, int *degrees, int N) {
    FILE *f = fopen(filename, "w");
    fprintf(f, "p,clustering,path_length,avg_degree\n");
    
    int total_degree = 0;
    for (int i = 0; i < N; i++) total_degree += degrees[i];
    
    fprintf(f, "%.4f,%.4f,%.4f,%.2f\n", 
            p, clustering, path_length, total_degree/(float)N);
    
    fclose(f);
}
```

**Output files:**
```
output/
â”œâ”€â”€ edges_p0.000.csv    (5000 rows: source,target pairs)
â”œâ”€â”€ edges_p0.010.csv
â”œâ”€â”€ edges_p0.100.csv
â”œâ”€â”€ edges_p1.000.csv
â”œâ”€â”€ metrics_p0.000.csv  (1 row: p, clustering, path_length)
â”œâ”€â”€ metrics_p0.010.csv
â””â”€â”€ ...
```

---

### Python Visualization Script

**Embedded in `10_visualization_python.cu` as comment:**

```python
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd

def load_graph(p):
    """Load graph from CSV"""
    df = pd.read_csv(f'output/edges_p{p:.3f}.csv')
    G = nx.from_pandas_edgelist(df, 'source', 'target')
    return G

def visualize_network(p):
    """Visualize single network"""
    G = load_graph(p)
    
    # Choose layout based on p
    if p < 0.01:
        pos = nx.circular_layout(G)  # Ring for regular
    elif p > 0.9:
        pos = nx.spring_layout(G)    # Force-directed for random
    else:
        pos = nx.spring_layout(G, k=0.3)  # Small-world
    
    plt.figure(figsize=(10, 10))
    nx.draw(G, pos, node_size=20, edge_color='gray', alpha=0.5)
    plt.title(f'Watts-Strogatz (p={p:.3f})')
    plt.savefig(f'output/network_p{p:.3f}.png', dpi=150)

def plot_phase_transition():
    """Plot C and L vs p"""
    p_values = [0.0, 0.001, 0.01, 0.1, 1.0]
    C_values = []
    L_values = []
    
    for p in p_values:
        metrics = pd.read_csv(f'output/metrics_p{p:.3f}.csv')
        C_values.append(metrics['clustering'][0])
        L_values.append(metrics['path_length'][0])
    
    # Normalize
    C_norm = [c / C_values[0] for c in C_values]
    L_norm = [l / L_values[0] for l in L_values]
    
    plt.figure(figsize=(10, 6))
    plt.plot(p_values, C_norm, 'o-', label='C(p) / C(0)', linewidth=2)
    plt.plot(p_values, L_norm, 's-', label='L(p) / L(0)', linewidth=2)
    plt.xscale('log')
    plt.xlabel('Rewiring Probability (p)')
    plt.ylabel('Normalized Value')
    plt.title('Small-World Phase Transition')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('output/phase_transition.png', dpi=150)
```

**Run the script:**
```bash
# Step 1: Generate data
nvcc 10_visualization_python.cu -o visualize -lcurand
./visualize

# Step 2: Visualize
python visualize.py

# Output: Beautiful plots in output/ directory!
```

---

### Advanced Visualizations

**1. Comparison Panel (3Ã—3 grid)**

```python
fig, axes = plt.subplots(3, 3, figsize=(15, 15))
p_samples = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0]

for i, p in enumerate(p_samples):
    G = load_graph(p)
    ax = axes[i // 3, i % 3]
    pos = get_layout(G, p)
    nx.draw(G, pos, ax=ax, node_size=10, edge_color='gray')
    ax.set_title(f'p={p:.3f}')
    
plt.tight_layout()
plt.savefig('output/comparison_panel.png', dpi=200)
```

**2. Animated Phase Transition**

```python
from matplotlib.animation import FuncAnimation

def animate(frame):
    p = frame / 100  # p from 0 to 1
    G = generate_or_load_graph(p)
    pos = nx.spring_layout(G)
    nx.draw(G, pos)
    plt.title(f'p = {p:.3f}')

anim = FuncAnimation(fig, animate, frames=100, interval=100)
anim.save('output/phase_transition.mp4', fps=10)
```

**3. Interactive Web Visualization**

```python
import plotly.graph_objects as go

# Create network graph with Plotly
edge_trace = go.Scatter(x=edge_x, y=edge_y, mode='lines')
node_trace = go.Scatter(x=node_x, y=node_y, mode='markers')

fig = go.Figure(data=[edge_trace, node_trace])
fig.write_html('output/interactive.html')
```

---

## Part 8: Advanced Topics

### Topic 1: Directed Watts-Strogatz

**Modification:** Edges have direction

```cuda
__global__ void createDirectedRing(int *src, int *dst, int N, int K) {
    // Only connect to K neighbors on RIGHT (no left connections)
    // Creates directed ring
}
```

**Applications:** Information flow, neural networks, citation networks

---

### Topic 2: Weighted Edges

**Add weight array:**

```cuda
struct Graph {
    int *offsets, *edges;
    float *weights;  // Edge weights
};

__global__ void rewireWeighted(int *dst, float *weights, ...) {
    // When rewiring, assign new weight
    if (random_val < p) {
        dst[edge_idx] = new_v;
        weights[edge_idx] = curand_uniform(&state);  // Random weight
    }
}
```

**Applications:** Social strength, traffic capacity, neural weights

---

### Topic 3: Dynamic Networks

**Time-varying rewiring probability:**

```cuda
__global__ void rewireDynamic(int *dst, float *p_array, int timestep, ...) {
    float p = p_array[timestep];  // Different p over time
    // Rewire with time-dependent probability
}
```

**Applications:** Evolving social networks, neural plasticity

---

### Topic 4: Multi-GPU Scaling

**Challenge:** Network doesn't fit in one GPU

**Solution:** Partition nodes across GPUs

```cuda
// GPU 0: nodes 0-499
// GPU 1: nodes 500-999

// Each GPU generates its portion
cudaSetDevice(0);
createRingLattice<<<...>>>(dev0_src, dev0_dst, 0, 500, ...);

cudaSetDevice(1);
createRingLattice<<<...>>>(dev1_src, dev1_dst, 500, 1000, ...);

// Handle cross-GPU edges with peer-to-peer transfer or NCCL
```

---

### Topic 5: Alternative Small-World Models

**Newman-Watts model:**
- Keep all original edges
- ADD shortcuts (don't rewire)
- Result: Never disconnects the graph

**Kleinberg model:**
- 2D lattice instead of ring
- Long-range connections with distance-dependent probability
- Used in distributed systems

**BarabÃ¡si-Albert model:**
- "Rich get richer" (preferential attachment)
- Creates scale-free networks (power-law degree distribution)
- Complementary to Watts-Strogatz

---

## ğŸ“ Summary

### What We Learned

1. **Small-World Networks:**
   - High clustering (like regular lattices)
   - Short paths (like random graphs)
   - Ubiquitous in nature and society

2. **Watts-Strogatz Model:**
   - Start with ring lattice (ordered)
   - Rewire with probability p
   - Phase transition at p â‰ˆ 0.001-0.01

3. **GPU Implementation:**
   - Ring lattice: Perfect parallelism, coalesced memory
   - Rewiring: cuRAND for parallel randomness
   - CSR conversion: Efficient graph storage

4. **Phase Transition:**
   - Path length drops exponentially with p
   - Clustering decays gradually
   - Small-world emerges when Lâ‰ˆL(random) but Câ‰ˆC(lattice)

5. **Visualization:**
   - CUDA â†’ CSV â†’ Python â†’ Plots
   - NetworkX for layout and metrics
   - Interactive exploration of parameter space

---

### Key Takeaways

> *"A few random connections can transform a slow, clustered network into a fast, efficient oneâ€”without destroying its local structure. This is the power of small-world networks."*

âœ… **Theoretical:** Phase transitions emerge from simple rules  
âœ… **Computational:** GPU parallelism enables large-scale network generation  
âœ… **Practical:** Visualization bridges computation and intuition  
âœ… **Applicable:** Model applies to diverse real-world systems  

---

### Connection to Code Files

**`7_watts_strogatz.cu`** demonstrates:
- Ring lattice construction (thread-per-node)
- Parallel rewiring with cuRAND
- Warp divergence challenges
- CSR conversion

**`10_visualization_python.cu`** demonstrates:
- Data export pipeline
- Python integration
- NetworkX visualization
- Phase transition plots

**Both show:** How GPU computation enables exploration of network science at scale!

---

## ğŸ‹ï¸ Practice Exercises

### Exercise 1: Implement Newman-Watts Model

Instead of rewiring, ADD shortcuts:

```cuda
__global__ void addShortcuts(int *src, int *dst, int original_edges, 
                             int N, float p, ...) {
    // Add new edges WITHOUT removing old ones
    // Hint: Allocate extra space for new edges
}
```

**Challenge:** How do you know how many edges to allocate?

---

### Exercise 2: 2D Lattice Version

Extend to 2D grid instead of ring:

```cuda
__global__ void create2DLattice(int *src, int *dst, int W, int H) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (x < W && y < H) {
        int node = y * W + x;
        
        // Connect to 4 neighbors (up, down, left, right)
        // YOUR CODE HERE
    }
}
```

---

### Exercise 3: Measure Robustness

Compute how removal of nodes affects network:

```cuda
// Remove fraction f of nodes randomly
// Measure: Average path length, largest component size
// Plot: Robustness vs p (regular vs small-world vs random)
```

**Expected:** Small-world networks are surprisingly robust!

---

### Exercise 4: Animate Network Evolution

Generate frames for different p values:

```bash
# Generate 100 networks (p = 0.00 to 1.00)
for p in 0.00 0.01 0.02 ... 1.00:
    ./visualize $p
    python plot_single.py $p

# Combine into video
ffmpeg -i output/frame_%03d.png -c:v libx264 evolution.mp4
```

---

## ğŸ”— What's Next?

In **Blog 6**, we'll master **optimization and profiling**:
- Finding bottlenecks with Nsight tools
- Memory coalescing optimization
- Reducing warp divergence
- Achieving maximum performance

In **Blog 7**, we'll explore:
- Advanced graph algorithms (PageRank, community detection)
- Multi-GPU implementations
- Real-world network analysis

**Files to explore:**
- `9_optimization_profiling.cu` - Performance tuning
- Real-world datasets (Stanford SNAP, NetworkX examples)

---

## ğŸ“š Additional Resources

**Foundational Papers:**
- [Watts & Strogatz (1998)](https://www.nature.com/articles/30918) - Original small-world paper
- [Newman & Watts (1999)](https://www.sciencedirect.com/science/article/pii/S0375960199003571) - Renormalization group analysis
- [Kleinberg (2000)](https://www.cs.cornell.edu/home/kleinber/networks-book/) - Navigation in small-world networks

**Books:**
- "Networks, Crowds, and Markets" - Easley & Kleinberg
- "Network Science" - BarabÃ¡si (free online)
- "The Structure and Dynamics of Networks" - Newman et al.

**Software:**
- [NetworkX](https://networkx.org/) - Python graph library
- [igraph](https://igraph.org/) - Fast C library with Python bindings
- [graph-tool](https://graph-tool.skewed.de/) - High-performance Python

**Datasets:**
- [Stanford SNAP](http://snap.stanford.edu/data/) - Large network datasets
- [Network Repository](http://networkrepository.com/) - 5000+ networks
- [Koblenz Network Collection](http://konect.cc/) - Social, biological, technological

---

## ğŸ’¡ Final Thought

> *"The Watts-Strogatz model taught us that complex emergent behaviorâ€”like the small-world phenomenonâ€”doesn't require complex mechanisms. Simple local rules + a bit of randomness = global magic. And with GPUs, we can explore these emergent properties at unprecedented scale."*

You've now mastered:
- **The Theory**: Small-world networks and phase transitions
- **The Implementation**: Parallel network generation on GPU
- **The Analysis**: Computing clustering and path length
- **The Visualization**: Bringing data to life

**Next stop: Optimizing everything to run 100Ã— faster!** ğŸš€

---

**Next:** [Blog 6: Optimization and Profiling](./blog_6.md) â†’

**Previous:** [Blog 4: Graph Representations](./blog_4.md) â†

---

*Questions? Generated an interesting network? Share your visualizations!*
